# Copyright 2023 Ant Group Co., Ltd.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1
parameters:
  GHA_Actor:
    type: string
    default: ""
  GHA_Action:
    type: string
    default: ""
  GHA_Event:
    type: string
    default: ""
  GHA_Meta:
    type: string
    default: ""

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
jobs:
  build_binary:
    # Specify the execution environment. You can specify an image from Dockerhub or use one of our Convenience Images from CircleCI's Developer Hub.
    # See: https://circleci.com/docs/2.0/configuration-reference/#docker-machine-macos-windows-executor
    docker:
      - image: secretflow/scql-ci:latest
    parameters:
      resource_class:
        type: string
    resource_class: << parameters.resource_class >>
    shell: /bin/bash --login -eo pipefail
    # Add steps to the job
    # See: https://circleci.com/docs/2.0/configuration-reference/#steps
    steps:
      - checkout
      - run:
          name: "Checkout devtools"
          command: git clone https://github.com/secretflow/devtools.git ../devtools
      - run:
          name: Setup GCS
          command: |
            echo ${gcs_content} > ../gcs.data
            ../devtools/bazel_cache_setup.py --in_file=../gcs.data --out_file=gcs.json --min_download
      - run:
          name: "Build"
          command: |
            make binary
      - run:
          name: "Copy binary"
          command: |
            MACHINE_TYPE=`arch`
            if [ ${MACHINE_TYPE} == 'x86_64' ]; then
              DIR=/tmp/binary/linux/amd64/
            else
              DIR=/tmp/binary/linux/arm64/
            fi
            mkdir -p ${DIR}
            cp bazel-bin/engine/exe/scqlengine ${DIR}
            cp bin/scdbserver ${DIR}
            cp bin/scdbclient ${DIR}
            cp bin/broker ${DIR}
            cp bin/brokerctl ${DIR}
            ls ${DIR}
      - persist_to_workspace:
          root: "/tmp/binary/linux"
          paths:
            - amd64/*
            - arm64/*
  docker_image_publish:
    docker:
      - image: cimg/deploy:2023.06.1
    steps:
      - checkout
      - setup_remote_docker
      - attach_workspace:
          at: /tmp/binary/linux
      - run:
          name: Build Docker image
          command: |
            # login dockerhub & secretflow aliyun docker registry
            docker login -u secretflow -p ${DOCKER_DEPLOY_TOKEN}
            docker login -u ${ALIYUN_DOCKER_USERNAME} -p ${ALIYUN_DOCKER_PASSWORD}  secretflow-registry.cn-hangzhou.cr.aliyuncs.com

            ALIYUN_IMAGE="secretflow-registry.cn-hangzhou.cr.aliyuncs.com/secretflow/scql"

            ls /tmp/binary/linux/amd64/
            ls /tmp/binary/linux/arm64/

            # Build image
            cd docker
            mkdir -p linux/amd64
            mkdir -p linux/arm64
            cp /tmp/binary/linux/amd64/scqlengine linux/amd64/scqlengine
            cp /tmp/binary/linux/amd64/scdbserver linux/amd64/scdbserver
            cp /tmp/binary/linux/amd64/scdbclient linux/amd64/scdbclient
            cp /tmp/binary/linux/amd64/broker     linux/amd64/broker
            cp /tmp/binary/linux/amd64/brokerctl  linux/amd64/brokerctl

            cp /tmp/binary/linux/arm64/scqlengine linux/arm64/scqlengine
            cp /tmp/binary/linux/arm64/scdbserver linux/arm64/scdbserver
            cp /tmp/binary/linux/arm64/scdbclient linux/arm64/scdbclient
            cp /tmp/binary/linux/arm64/broker     linux/arm64/broker
            cp /tmp/binary/linux/arm64/brokerctl  linux/arm64/brokerctl

            # copy scripts
            cp -r ../scripts ./scripts

            ls ./linux/amd64
            ls ./linux/arm64
            ls ./scripts

            TAG=$(grep "version" ../version.txt | awk -F'"' '{print $2}')
            echo $TAG
            docker buildx create --name scql-image-builder --platform linux/arm64,linux/amd64 --use
            docker buildx build --platform linux/arm64,linux/amd64 -f scql-ubuntu.Dockerfile -t secretflow/scql:$TAG --push .
            docker buildx build --platform linux/arm64,linux/amd64 -f scql-ubuntu.Dockerfile -t secretflow/scql:latest --push .
            docker buildx build --platform linux/arm64,linux/amd64 -f scql-ubuntu.Dockerfile -t secretflow/scql:stable --push .

            # push to aliyun image repo
            docker buildx build --platform linux/arm64,linux/amd64 -f scql-ubuntu.Dockerfile -t ${ALIYUN_IMAGE}:$TAG --push .
            docker buildx build --platform linux/arm64,linux/amd64 -f scql-ubuntu.Dockerfile -t ${ALIYUN_IMAGE}:latest --push .
            docker buildx build --platform linux/arm64,linux/amd64 -f scql-ubuntu.Dockerfile -t ${ALIYUN_IMAGE}:stable --push .

# Invoke jobs via workflows
# See: https://circleci.com/docs/2.0/configuration-reference/#workflows
workflows:
  publish:
    jobs:
      - build_binary:
          matrix:
            parameters:
              resource_class: ["2xlarge", "arm.2xlarge"]
          # This is mandatory to trigger a pipeline when pushing a tag
          filters:
            tags:
              only: /.*/
      - docker_image_publish:
          requires:
            - build_binary
          # This is mandatory to trigger a pipeline when pushing a tag
          filters:
            tags:
              only: /.*/
